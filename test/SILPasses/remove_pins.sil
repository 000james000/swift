// RUN: %target-sil-opt -remove-pins -verify %s | FileCheck %s

sil_stage canonical

import Swift
import SwiftShims
import Builtin

/////////////
// Utility //
/////////////

struct ArrayIntBuffer {
  var storage : Builtin.NativeObject
}

struct ArrayInt{
  var buffer : ArrayIntBuffer
}

sil [_semantics "array.make_mutable"] @make_mutable : $@convention(method) (@inout ArrayInt) -> Bool

sil [_semantics "array.get_count"] @get_count : $@convention(method) (@guaranteed ArrayInt) -> ()

sil @user : $@convention(thin) (Builtin.NativeObject) -> Bool

///////////
// Tests //
///////////

// CHECK-LABEL: sil @remove_pins
// CHECK-NOT: strong_pin
// CHECK-NOT: strong_unpin
// CHECK: return

sil @remove_pins : $@convention(thin) (@guaranteed Builtin.NativeObject) -> () {
bb0(%0 : $Builtin.NativeObject):
  %1 = strong_pin %0 : $Builtin.NativeObject
  strong_unpin %1 : $Optional<Builtin.NativeObject>
  %2 = tuple()
  return %2 : $()
}

// CHECK-LABEL: sil @dont_remove_pins
// CHECK: strong_pin
// CHECK: strong_release
// CHECK: strong_unpin
// CHECK: return

sil @dont_remove_pins : $@convention(thin) (@guaranteed Builtin.NativeObject) -> () {
bb0(%0 : $Builtin.NativeObject):
  %1 = strong_pin %0 : $Builtin.NativeObject
  strong_release %0 : $Builtin.NativeObject
  strong_unpin %1 : $Optional<Builtin.NativeObject>
  %2 = tuple()
  return %2 : $()
}

/// Due to the usage pattern of the array's uniquing there will always be a
/// guarding make_mutable across the second access of a non-structural
/// modification sequence.

// CHECK-LABEL: sil @remove_pins_across_make_mutable
// CHECK: [[MAKE_MUTABLE:%.*]] = function_ref @make_mutable
// CHECK: apply [[MAKE_MUTABLE]]
// CHECK-NOT: strong_pin
// CHECK: apply [[MAKE_MUTABLE]]
// CHECK-NOT: strong_unpin
// CHECK: return

sil @remove_pins_across_make_mutable : $@convention(thin) (@inout ArrayInt) -> () {
bb0(%0 : $*ArrayInt):
  %1 = load %0: $*ArrayInt
  %2 = struct_extract %1 : $ArrayInt, #ArrayInt.buffer
  %3 = struct_extract %2 : $ArrayIntBuffer, #ArrayIntBuffer.storage
  %4 = function_ref @make_mutable : $@convention(method) (@inout ArrayInt) -> Bool
  %5 = apply %4(%0) : $@convention(method) (@inout ArrayInt) -> Bool
  %6 = strong_pin %3 : $Builtin.NativeObject
  %7 = apply %4(%0) : $@convention(method) (@inout ArrayInt) -> Bool
  strong_unpin %6 : $Optional<Builtin.NativeObject>
  %8 = tuple()
  return %8 : $()
}

// CHECK-LABEL: sil @dont_remove_pins_across_pin_read
// CHECK: strong_pin
// CHECK: is_unique_or_pinned
// CHECK: strong_unpin

sil @dont_remove_pins_across_pin_read : $@convention(thin) (@inout ArrayInt) -> Builtin.Int1 {
bb0(%0 : $*ArrayInt):
  %1 = load %0: $*ArrayInt
  %2 = struct_element_addr %0 : $*ArrayInt, #ArrayInt.buffer
  %3 = struct_element_addr %2 : $*ArrayIntBuffer, #ArrayIntBuffer.storage
  %4 = struct_extract %1 : $ArrayInt, #ArrayInt.buffer
  %5 = struct_extract %4 : $ArrayIntBuffer, #ArrayIntBuffer.storage
  %6 = strong_pin %5 : $Builtin.NativeObject
  %7 = is_unique_or_pinned %3 : $*Builtin.NativeObject
  strong_unpin %6 : $Optional<Builtin.NativeObject>
  return %7 : $Builtin.Int1
}

// CHECK-LABEL: sil @remove_pins_with_inert_rcidentity_uses : $@convention(thin) (@inout ArrayInt) -> () {
// CHECK-NOT: strong_pin
// CHECK-NOT: strong_unpin
sil @remove_pins_with_inert_rcidentity_uses : $@convention(thin) (@inout ArrayInt) -> () {
bb0(%0 : $*ArrayInt):
  %1 = load %0: $*ArrayInt
  %2 = struct_extract %1 : $ArrayInt, #ArrayInt.buffer
  %3 = struct_extract %2 : $ArrayIntBuffer, #ArrayIntBuffer.storage
  %4 = unchecked_trivial_bit_cast %3 : $Builtin.NativeObject to $UnsafePointer<HeapObject>
  %6 = strong_pin %3 : $Builtin.NativeObject
  %7 = integer_literal $Builtin.Int1, 0
  %8 = tuple(%6 : $Optional<Builtin.NativeObject>, %7 : $Builtin.Int1)
  %9 = tuple_extract %8 : $(Optional<Builtin.NativeObject>, Builtin.Int1), 0
  strong_unpin %9 : $Optional<Builtin.NativeObject>
  %9999 = tuple()
  return %9999 : $()
}

// CHECK-LABEL: sil @cant_remove_pins_with_escaping_rcidentity_use : $@convention(thin) (@inout ArrayInt) -> Bool {
// CHECK: strong_pin
// CHECK: strong_unpin
sil @cant_remove_pins_with_escaping_rcidentity_use : $@convention(thin) (@inout ArrayInt) -> Bool {
bb0(%0 : $*ArrayInt):
  %1 = load %0: $*ArrayInt
  %4 = struct_extract %1 : $ArrayInt, #ArrayInt.buffer
  %5 = struct_extract %4 : $ArrayIntBuffer, #ArrayIntBuffer.storage
  %6 = strong_pin %5 : $Builtin.NativeObject
  %7 = integer_literal $Builtin.Int1, 0
  %8 = tuple(%6 : $Optional<Builtin.NativeObject>, %7 : $Builtin.Int1)
  %9 = tuple_extract %8 : $(Optional<Builtin.NativeObject>, Builtin.Int1), 0
  strong_unpin %9 : $Optional<Builtin.NativeObject>
  %11 = unchecked_enum_data %6 : $Optional<Builtin.NativeObject>, #Optional.Some!enumelt.1
  %12 = function_ref @user : $@convention(thin) (Builtin.NativeObject) -> Bool
  %13 = apply %12(%11) : $@convention(thin) (Builtin.NativeObject) -> Bool
  return %13 : $Bool
}

// Make sure we ignore the uses of %10 and %12.
//
// This is safe to do since the value we are extracting has nothing to do really
// with the RCIdentity of the tuple we are extracting from.

// CHECK-LABEL: sil @remove_pins_with_inert_rcidentity_uses3 : $@convention(thin) (@inout ArrayInt) -> (Builtin.Int1, Builtin.Int1) {
// CHECK-NOT: strong_pin
// CHECK-NOT: strong_unpin
sil @remove_pins_with_inert_rcidentity_uses3 : $@convention(thin) (@inout ArrayInt) -> (Builtin.Int1, Builtin.Int1) {
bb0(%0 : $*ArrayInt):
  %1 = load %0: $*ArrayInt
  %2 = struct_extract %1 : $ArrayInt, #ArrayInt.buffer
  %3 = struct_extract %2 : $ArrayIntBuffer, #ArrayIntBuffer.storage
  %4 = unchecked_trivial_bit_cast %3 : $Builtin.NativeObject to $UnsafePointer<HeapObject>
  %6 = strong_pin %3 : $Builtin.NativeObject
  %7 = integer_literal $Builtin.Int1, 0
  %8 = tuple(%6 : $Optional<Builtin.NativeObject>, %7 : $Builtin.Int1)
  %9 = tuple_extract %8 : $(Optional<Builtin.NativeObject>, Builtin.Int1), 0
  %10 = tuple_extract %8 : $(Optional<Builtin.NativeObject>, Builtin.Int1), 1
  strong_unpin %9 : $Optional<Builtin.NativeObject>  
  %11 = tuple_extract %8 : $(Optional<Builtin.NativeObject>, Builtin.Int1), 1
  %12 = tuple(%10 : $Builtin.Int1, %11 : $Builtin.Int1)
  return %12 : $(Builtin.Int1, Builtin.Int1)
}

// CHECK-LABEL: sil @do_not_remove_pins_non_inert_rcidentity_uses : $@convention(thin) (@inout ArrayInt) -> Bool {
// CHECK: strong_pin
// CHECK: strong_unpin
sil @do_not_remove_pins_non_inert_rcidentity_uses : $@convention(thin) (@inout ArrayInt) -> Bool {
bb0(%0 : $*ArrayInt):
  %1 = load %0: $*ArrayInt
  %2 = struct_extract %1 : $ArrayInt, #ArrayInt.buffer
  %3 = struct_extract %2 : $ArrayIntBuffer, #ArrayIntBuffer.storage
  %4 = unchecked_trivial_bit_cast %3 : $Builtin.NativeObject to $UnsafePointer<HeapObject>
  %6 = strong_pin %3 : $Builtin.NativeObject
  %7 = integer_literal $Builtin.Int1, 0
  %8 = tuple(%6 : $Optional<Builtin.NativeObject>, %7 : $Builtin.Int1)
  %9 = tuple_extract %8 : $(Optional<Builtin.NativeObject>, Builtin.Int1), 0
  strong_unpin %9 : $Optional<Builtin.NativeObject>
  %10 = unchecked_ref_bit_cast %9 : $Optional<Builtin.NativeObject> to $Builtin.NativeObject
  %11 = function_ref @user : $@convention(thin) (Builtin.NativeObject) -> Bool
  %12 = apply %11(%10) : $ @convention(thin) (Builtin.NativeObject) -> Bool
  return %12 : $Bool
}

// Make sure that we properly ignore guaranteed retain, releases.
//
// Discussion: We pattern match very closely for now by whenever we see a
// release, checking if the previous instruction was a guaranteed array semantic
// call with guaranteed self and the instruction before that a retain on self
// again. In such a case, we ignore the release.
//
// CHECK-LABEL: sil @pins_and_guaranteed_self : $@convention(thin) (@inout ArrayInt) -> () {
// CHECK: bb0
// CHECK-NOT: strong_pin
// CHECK-NOT: strong_unpin
// CHECK: bb1
// CHECK: strong_pin
// CHECK: strong_unpin
sil @pins_and_guaranteed_self : $@convention(thin) (@inout ArrayInt) -> () {
bb0(%0 : $*ArrayInt):
  %1 = load %0: $*ArrayInt
  %2 = struct_extract %1 : $ArrayInt, #ArrayInt.buffer
  %3 = struct_extract %2 : $ArrayIntBuffer, #ArrayIntBuffer.storage
  %4 = unchecked_trivial_bit_cast %3 : $Builtin.NativeObject to $UnsafePointer<HeapObject>
  %6 = function_ref @get_count : $@convention(method) (@guaranteed ArrayInt) -> ()
  %7 = strong_pin %3 : $Builtin.NativeObject
  retain_value %1 : $ArrayInt
  apply %6(%1) : $@convention(method) (@guaranteed ArrayInt) -> ()
  release_value %1 : $ArrayInt
  strong_unpin %7 : $Optional<Builtin.NativeObject>

  // We take advantage of pins being single BB here.
  br bb1

bb1:
  %8 = strong_pin %3 : $Builtin.NativeObject
  retain_value %1 : $ArrayInt
  apply %6(%1) : $@convention(method) (@guaranteed ArrayInt) -> ()
  apply %6(%1) : $@convention(method) (@guaranteed ArrayInt) -> ()
  release_value %1 : $ArrayInt
  strong_unpin %8 : $Optional<Builtin.NativeObject>

  %9999 = tuple()
  return %9999 : $()
}

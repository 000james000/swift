<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8">
	<title>string types</title>

    <style type="text/css">
        h1 {text-align:center;}
        p  {text-align:justify;}
        blockquote.note
        {
            background-color:#E0E0E0;
            padding-left: 15px;
            padding-right: 15px;
            padding-top: 1px;
            padding-bottom: 1px;
        }
        ins {background-color:#A0FFA0;}
        del {background-color:#FFA0A0;}
        address {text-align:right;}
        h1 {text-align:center;}
        span.comment {color:#C80000;}
        table {border-width:1px; border-color:black; border-style:solid;}
        td {border-width:1px; border-color:black; border-style:solid; padding:5px;}
        img {float:right;}
        overbar {text-decoration:overline;}
    </style>

</head>
<body>

<address align=right>
<a href="mailto:hhinnant@apple.com">Howard Hinnant</a><br>

2011-07-22
</address>
<hr>

<h1>Language Independent String Data Structures</h1>

<p>
This document illustrates several string data structures.  All of them are
valuable from both an efficiency and functionality point of view.  The intent of
this document is to form a basis for discussion.  The intent of this document is
<b>not</b> to demonstrate that one data structure is better than all the rest.
</p>

<p>
For now, these data structures will be called <code>S0</code>, <code>S1</code>,
<code>S2</code>, etc.  That is, I don't want to prematurely anoint one of these
types with the name <code>string</code>.  Thus these generic and ugly names are
used here for discussion purposes only.  The names <code>S0</code>,
<code>S1</code>, <code>S2</code>, etc. are not proposed.  For all of these data
structures the following assumptions are currently being made.  None of these
assumptions is terribly important at this point as they can all easily be
changed for each of these data structures in an identical way.
</p>

<ul>
<li>The data of a string is stored in memory as a contiguous array of bytes.</li>
<li>The data of the string is encoded as UTF-8.</li>
<li>The number of bytes it takes to represent the data is stored in the
word just prior to the string data.</li>
</ul>

<p>
Not shown in these data structures, but could easily be added:
</p>

<ul>
<li>A terminating null byte at the end of the string data.</li>
<li>A word to store the number of code points in the data.</li>
</ul>

<h2><code>S0</code></h2>

<img src="s0.tiff" alt="string type s0" />

<p>
<code>S0</code> models an immutable string which can be constructed without
allocating heap memory.  The contents of the string must be known at compile
time.  This is a candidate for the type of a string literal.  To construct such
a string you merely point to its representation in rom. The pointer is the
type's only data member.
</p>

<p>
<code>S0</code> can be very cheaply copy constructed by simply copy constructing
the pointer.
</p>

<p>
<code>S0</code> can be very cheaply copy assigned by simply copy assigning
the pointer.
</p>

<p>
Destruction of an object of type <code>S0</code> is a no-op.
</p>

<p>
<code>S0</code> can not be used to model strings containing data unknown until
run time.
</p>

<p>
<code>S0</code> can not be used to model mutable strings.
</p>

<p>
Candidate functionality for <code>S0</code> should include:
</p>

<ul>
<li>Construction from a string literal.</li>
<li>Copy construction.</li>
<li>Copy assignment.</li>
<li>A getter for the number of bytes used to hold the data.  This should be a
compile-time constant.</li>
<li>A getter for the number of code points stored in the data..  This should be
a compile-time constant.</li>
<li>A system for getting each code point in order.  If there exists a
compile-time way of selecting a code point, and the selection is done at compile
time, then the resulting code point should be a compile-time constant.</li>
<li>Some API to efficiently copy the data, or a subset of it starting and ending
at code point boundaries, to some other memory location (one code point at a
time is too slow).</li>
</ul>

<p>
If a string literal <i>is</i> an <code>S0</code> then it would be best if all of
the functionality worked directly with a string literal instead of having to
explicitly construct an <code>S0</code> from the literal.  For example here
is some go code:
</p>

<blockquote><pre>
var i = len("a string literal")
</pre></blockquote>

<h2><code>S1</code></h2>

<img src="s1.tiff" alt="string type s1" />

<p>
<code>S1</code> models an immutable string which can hold contents not known
until run time.  This is a candidate for the type of a string literal. To
construct such a string one must dynamically allocate memory to hold a reference
count in addition to the string data. The pointer is the type's only data
member.
</p>

<p>
Note that the <i>shared ownership pointer</i> is always a "strong" reference.
And if the API for this type is such that references to the string data are
never exposed, then there is no motivation to support "weak" references to this
data structure.  The importance of this observation is that to support weak
references, there must be two reference counts.  If only strong references need
be supported, one reference count suffices.
</p>

<p>
Construction from a string literal is more expensive for <code>S1</code> than
for <code>S0</code> because of the need to allocate memory, and copy the string
data from rom into the allocated memory.
</p>

<p>
<code>S1</code> copy construction involves an atomic increment of the reference
count.
</p>

<p>
<code>S1</code> copy assignment involves both an atomic increment and decrement
of the reference count.
</p>

<p>
<code>S1</code> destruction involves an atomic decrement of the reference count,
and on zero ownership, deallocation of the allocated memory.  If this data
structure is modified to support weak references, two atomic decrements will be
necessary.
</p>

<p>
If <code>S1</code> supports a <i>resource-less state</i>, that is, a state where
the shared ownership pointer does not point to allocated memory, then an
optimization is possible for copy constructing and copy assigning when the
source of the copy is an rvalue (or temporary).  This is what is called <i>move
semantics</i> in C++11.  The <del>copy</del> move construction from an rvalue
<code>S1</code> can take place without any atomic operations at all.  And the
<del>copy</del> move assignment can take place with one atomic operation instead
of two.
</p>

<h2><code>S1<sup>+</sup></code></h2>

<img src="s1+.tiff" alt="string type s1+" />

<p>
The <code>S0</code> data structure is not better than the <code>S1</code> data
structure, and vice-versa.  <code>S0</code> is faster and uses less memory.
It has fail-safe construction.  But it can only hold data known at compile time.
<code>S1</code> can hold data not known until run time, but has performance and
space penalties relative to <code>S0</code>.
</p>

<p>
A hybrid of these data structures should be a consideration.  This is an attempt
to get the best of <code>S0</code> and <code>S1</code> under one type name.
<code>S1<sup>+</sup></code> holds a discriminated union of the pointer types
stored in <code>S0</code> and <code>S1</code>.  Thus assuming the space for the
discriminator can be optimized away, the <code>sizeof S1<sup>+</sup></code> is
still just one pointer.
</p>

<p>
The <code>S1<sup>+</sup></code> type chooses which type of pointer is active
based on whether the data it is constructed with is compile-time (i.e. a string
literal) or run time (e.g. an array slice of characters).  Such a data structure
has no space penalties over <code>S0</code> and <code>S1</code>, and its
performance adapts at run time depending on whether or not it is pointing into
rom.
</p>

<p>
It is a bit more complicated than <code>S0</code> and <code>S1</code>, but not
overly so.  And I believe that <code>S1<sup>+</sup></code> (like <code>S0</code>
and <code>S1</code>) is a viable candidate to be the type of a string literal.
</p>

<h2><code>S2</code></h2>

<img src="s2.tiff" alt="string type s2" />

<p>
The last string type I would like to discuss is one that will model mutable
strings.  This type is not a candidate for the type of string literal because a
string literal is not mutable. Most programming languages include a mutable
string type.  The reason is performance.  While it is true that you can build
any string in the world out of immutable strings, it is also well known that
there are common use cases where doing so can lead to quadratic run times
instead of linear run times.
</p>

<p>
Thus for a language to become a practical general purpose language, it must
support a model for mutable strings (that support can of course be in library
form instead of baked into the language).
</p>

<p>
Experience with Java and C++ appears to strongly indicate that mutable objects
should have value semantics.  That is, if you modify an object local to your
scope, there should be no danger that other parts of the program will see your
modifications.
</p>

<p>
Further experience with C++ has conclusively demonstrated that reference counted
implementations of mutable strings (commonly referred to as COW - Copy On Write)
are not effective, especially in a multithreaded environment.
</p>

<p>
Pictured here as <code>S2</code> is a simplified view of the data structure
used for mutable strings in libc++.  At its most basic it is nothing more than
an exclusively owning pointer to a dynamically allocated array of bytes, and
two additional data members indicating the current logical size in bytes of
the data, and a capacity (in bytes) which allows the size of the string to
grow without reallocation until size threatens to exceed capacity.
</p>

<p>
Capacity grows geometrically (typically by a factor between
(1+&radic;<overbar>5</overbar>)/2 and 2).  Thus even if the client adds to the
size only one byte at a time, doing so has amortized constant complexity.  If
the capacity grew by a constant amount, then the average cost of adding a byte
would be linear.
</p>

<p>
In C++11 the <code>S2</code> data structure takes advantage of move semantics.
The move constructor, which is automatically called instead of the copy constructor
when the source is an rvalue, does not allocate memory.  Instead it simply transfers
ownership of the memory block from source to target (assigns the pointer, nulling
the source).  The move assignment operator is similar.  Use of move semantics
allows data structures such as <code>S2</code> to be passed around quite freely
with zero, or at least minimal memory, allocation taking place.
</p>

<p>
An implementation detail of the libc++ <code>S2</code> data structure is that
the structure shown in the figure is union'd with another structure that is an
array of bytes: the first byte is the current size, and the following bytes are
the bytes of the string.  This is called the <i>short string optimization</i>
and allows <code>S2</code> types to hold "short" strings without allocating a
memory block.  On 64 bit platforms the libc++ <code>S2</code> data structure has
a <code>sizeof</code> 3 words (24 bytes), and an internal "short string"
capacity of 23 bytes.
</p>

<p>
If the API of <code>S2</code> does not directly expose the string data, then
there will be no danger of dangling reference to the string data, and thus no
motivation for weak references to the string data.
</p>

<h2>String Concatenation</h2>

<p>
Regardless of the string data structure used, a common use case is to concatenate
two or more strings, storing the result into a string:
</p>

<blockquote><pre>
string s0 = ...
string s1 = ...
string s2 = ...
string s3 = ...
string s4 =  "a literal" + s0 + s1 + s2 + "another literal" + s3
</pre></blockquote>

<p>
Implemented naively, this operation can be a performance bottleneck.  A naive
implementation would concatenate two strings at a time, and return a new string
with just enough capacity to hold the concatenation of the two arguments.  In
the above example that would require 5 allocations (one for each +).  An optimum
solution would perform one allocation with sufficient capacity to hold the final
result.
</p>

<p>
This problem is severe enough that C++03 programmers will often code the above
problem like so:
</p>

<blockquote><pre>
string s0 = ...
string s1 = ...
string s2 = ...
string s3 = ...
string s4 =  "a literal" + s0
s4 += s1
s4 += s2
s4 += "another literal"
s4 += s3
</pre></blockquote>

<p>
While this may not achieve the optimal number of allocations (1), it will do
much better because the <code>capacity</code> of <code>s4</code> will grow
geometrically.
</p>

<p>
In C++11 the cost of the original formulation will be exactly the same as the
cost of the "+=" formulation because the temporary string data buffer will
automatically get transferred from temporary to temporary (due to implicit move
semantics), and that data buffer will grow geometrically.
</p>

<p>
Another solution is to build up a run time expression tree.  The expression tree
does not actually do any concatenation or memory allocation until the entire
tree is built and an attempt is made to store the result.  At this time the tree
can be traversed and the needed capacity can be computed.  This approach makes
only one memory allocation.  An example C++ implementation of it is found in
llvm/ADT/Twine.h.
</p>

<p>
Finally yet another implementation technique is to build the expression tree at
compile time.  This can be faster than building the tree at run time as the only
code executed at run time is the indexing of individual bytes from the various
string arguments.  In C++ this is referred to as <i>expression templates</i> and
is notoriously hard to code, yet produces very efficient executables.  The
<code>valarray</code> header in libc++ demonstrates this technique.  If this
technique is selected for Swift, I strongly encourage us to either build the
ability into the compiler, or to provide library tools to more easily allow the
coder to build compile time expressions.  The C++ implementation of this
technique is difficult enough to be practical for only the most expert C++
programmers.  If done however, it has large (positive) performance implications
for numerical code, especially linear algebra.
</p>

</body>
</html>
